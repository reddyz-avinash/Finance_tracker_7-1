# text_input.py
import os
import re
import langdetect
import logging
from datetime import datetime

# Setup logging
def setup_logger():
    logging.basicConfig(
        filename='app.log',
        filemode='a',
        format='%(asctime)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )
<<<<<<< HEAD
setup_logger()

class TextLoader:
    def _init_(self, file_path):
        self.file_path = file_path
        self.raw_text = ""
        self.cleaned_text = ""

    def file_exists(self):
        exists = os.path.exists(self.file_path)
        logging.info(f"File exists check for {self.file_path}: {exists}")
        return exists

    def read_file(self):
        if not self.file_exists():
            logging.error(f"File {self.file_path} not found.")
            raise FileNotFoundError("File does not exist.")
        with open(self.file_path, 'r', encoding='utf-8') as f:
            self.raw_text = f.read()
        logging.info("File read successfully.")

    def clean_text(self):
        if not self.raw_text:
            logging.warning("No raw text to clean.")
            return ""
        text = self.raw_text
        text = text.lower()
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s]', '', text)
        self.cleaned_text = text
        logging.info("Text cleaned.")
        return text

    def detect_language(self):
        try:
            lang = langdetect.detect(self.cleaned_text)
            logging.info(f"Detected language: {lang}")
            return lang
        except:
            logging.error("Language detection failed.")
            return "unknown"

    def save_cleaned(self, output_file='cleaned_text.txt'):
        if not self.cleaned_text:
            logging.warning("No cleaned text to save.")
            return
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(self.cleaned_text)
        logging.info(f"Cleaned text saved to {output_file}")
=======
def get_stats(self):
        return {
            'length': len(self.raw_text),
            'clean_length': len(self.cleaned_text),
            'num_lines': self.raw_text.count('\n'),
            'num_words': len(self.cleaned_text.split())
        }


def create_sample_file(path):
    sample_text = """Hello! This is a sample document.
It contains multiple lines, punctuation marks, and mixed-case letters.
We're testing how the Text Analyzer processes this input."""
    with open(path, 'w', encoding='utf-8') as f:
        f.write(sample_text)
    logging.info("Sample file created.")

def menu():
    print("\n=== Text Input Module ===")
    print("1. Load and clean text")
    print("2. Detect language")
    print("3. Show stats")
print("4. Save cleaned text")
    print("5. Exit")

def main():
    path = "sample.txt"
    if not os.path.exists(path):
        create_sample_file(path)

    processor = TextLoader(path)

    while True:
        menu()
        choice = input("Enter choice: ")
        if choice == '1':
            processor.read_file()
            processor.clean_text()
            print("Text loaded and cleaned.")
        elif choice == '2':
            lang = processor.detect_language()
            print("Detected Language:", lang)
        elif choice == '3':
            stats = processor.get_stats()
            for k, v in stats.items():
                print(f"{k}: {v}")
        elif choice == '4':
            processor.save_cleaned()
            print("Cleaned text saved.")
        elif choice == '5':
            print("Exiting...")
            break
        else:
            print("Invalid choice. Try again.")
    if _name_ == "_main_":
    main()

# text_statistics.py
import re
import string
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud

class TextStats:
    def _init_(self, text):
        self.text = text
        self.words = []
        self.sentences = []
        self.paragraphs = []

    def tokenize_words(self):
        self.words = self.text.split()
        return self.words

    def tokenize_sentences(self):
        self.sentences = re.split(r'[.!?]', self.text)
        self.sentences = [s.strip() for s in self.sentences if s.strip()]
        return self.sentences

    def tokenize_paragraphs(self):
        self.paragraphs = self.text.split('\n\n')
        return self.paragraphs

    def word_count(self):
        return len(self.words)
 def sentence_count(self):
        return len(self.sentences)

    def paragraph_count(self):
        return len(self.paragraphs)

    def word_frequencies(self):
        clean_words = [word.strip(string.punctuation).lower() for word in self.words if word]
        return Counter(clean_words)

    def most_common_words(self, n=10):
        return self.word_frequencies().most_common(n)

    def generate_wordcloud(self, output_file='wordcloud.png'):
        word_freq = self.word_frequencies()
        wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)
        plt.figure(figsize=(10, 5))
        plt.imshow(wc, interpolation='bilinear')
        plt.axis('off')
        plt.savefig(output_file)
        print(f"Wordcloud saved as {output_file}")
def export_report(self, filename='text_report.txt'):
        with open(filename, 'w') as f:
            f.write("=== Text Analysis Report ===\n")
            f.write(f"Total Words: {self.word_count()}\n")
            f.write(f"Total Sentences: {self.sentence_count()}\n")
            f.write(f"Total Paragraphs: {self.paragraph_count()}\n")
            f.write("\n--- Most Common Words ---\n")
            for word, freq in self.most_common_words(20):
                f.write(f"{word}: {freq}\n")
        print(f"Report exported to {filename}")

def demo_statistics():
    from text_input import TextLoader
    loader = TextLoader("sample.txt")
    loader.read_file()
    loader.clean_text()


    ts = TextStats(loader.cleaned_text)
    ts.tokenize_words()
    ts.tokenize_sentences()
    ts.tokenize_paragraphs()

    print("Words:", ts.word_count())
    print("Sentences:", ts.sentence_count())
    print("Paragraphs:", ts.paragraph_count())
    print("Top 10 Words:", ts.most_common_words())

    ts.generate_wordcloud()
    ts.export_report()

if _name_ == "_main_":
    demo_statistics()
>>>>>>> B

